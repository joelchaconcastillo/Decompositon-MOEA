\MOEAS{} that take into account the diversity on variable space are not novel.
%
Particularly, these kinds of techniques have been applied for multimodal multi-objective optimization~\cite{Liang:16},
i.e., for cases where distant solutions in terms of variable space are desired~\cite{deb2008omni, cuate2019variation}.
%
Such kinds of \MOEAS{} must maintain a large degree of diversity on variable space during the whole optimization process.
%
In contrast, our work analyses the hyphotesis that state-of-the-art techniques can be advanced further by explicitly managing
the diversity on the variable space, even if the performance is only measured in terms of metrics that only take into account 
the objective space.
%
Since our aim is different, using multimodal multi-objective optimizers that maintain a large diversity 
for the whole optimization process is counter-productive, 
so more advanced ways of integrating the control of diversity are required.
%
Thus, this section reviews some of the most important advances on diversity-aware techniques that motivated the
design of \AVSDMOEAD{}, which are a set of methods that were adopted to single-objective optimization.
%
Additionally, \MOEAS{} that have considered in some way the diversity on variable space and
state-of-the-art \MOEAS{} are summarized.

\subsection{Diversity-aware Single-objective Optimizers}

Attaining a proper balance between exploration and exploitation is one of the keys of sucessfull single-objective
\EAS{}~\cite{lin2009auto}.
%
Several strategies to acomplish this aim have been explored and one of the most promising is to alter the trend
of diversity in an explicit or implicit way~\cite{Joel:Crepinsek}.
%
This principle has encouraged the development of a vast quantinty of diversity managment techniques~\cite{pandey2014comparative}.
%
A common classification of these methods is based on the sort of components modified in the \EA{}.
%
A popular taxonomy identifies the following groups~\cite{Joel:Crepinsek}: \textit{selection-based}, \textit{population-based}, \textit{crossover/mutation-based}, \textit{fitness-based}, and \textit{replacement-based}.
%
Additionally it defines the categories \textit{uniprocess-driven} and \textit{multiprocess-driven}, depending on the number
of components that are altered.

\textit{Replacement-based} methods have yielded quite promising results in the last years.
%
One of the most popular proposals belonging to this group is the \textit{crowding} method, 
in which each new individual should replace similar individuals from the previous generation~\cite{mengshoel2014adaptive}.
%
Several variants of this strategy have been devised, such as the \textit{Restricted Tournament Selection} 
(\RTS{})~\cite{harik1995finding}.
%
A more recent approach that has shown to be quite effective in a wide quantity of single-objective problems~\cite{segura2016improving}
is based on the principle of biasing the decisions taken in the replacement phase by taking into consideration the 
stopping criterion and elepased period.
%
This design principle has been successfull in continuous problems~\cite{castillo2019differential} and discrete 
problems~\cite{segura2016improving,romero2018memetic}, including the problem proposed for Google Hash Code 2020, where the most
effective optimizer was designed using this design principle.
%
Specifically, initial phases of the optimization explicitly preserve a higher amount of diversity than final phases and the
change between these behaviours is gradual.
%
Given the success of this methodology in the single-objective case, we adopt it to design our novel \MOEA{}.


\subsection{Diversity on Variable Space in \MOEAS{}}\label{MOEAs:Diversity}

In spite of the vast quantinty of proposed \MOEAS{}, none of state-of-the-art techniques involve
explictly managing the diversity in the variable space, which is a remarkable difference with respect
to single-objective optimizers.
%
One of the main reasons behind this difference is probably that there is a relation between the diversity on the objective 
space and the diversity on the decision variable space, so even if the diversity on decision space is not controlled explicitly,
not so negative effects as in single-objective optimization usually appear.
%
%Additionally, it is easy to proof that enforcing a minimum threshold for diversity on variable space for the whole optimization
%is not in general a good idea.
%
%In fact, we can imagine a problem where all Pareto Optimal solutions are close to each other in the variable space, meaning
%that enforcing diversity on variable space would provoke a degradation on performance on such kinds of problems.
However, the relation between the two different diversities depend on each \MOP{}~\cite{shir2009enhancing}, meaning
that including the successful principles of single-objective optimizers might result in more robust \MOEAS{}.
%
Most current \MOEAS{} that take into account diversity on the variable space are devoted to multimodal multi-objective optimization.
%
However, some attemps to apply these mechanisms in traditional multi-objective optimization have also been done.

The Non-Dominated Sorting Genetic Algorithm (\NSGA{}) developed in 1995~\cite{srinivas1994muiltiobjective} 
was one of the first \MOEAS{} that employed diversity on the variable space.
%
Particularly, fitness sharing is used to discriminate between solutions in the same front.
%
%However, this decision was at the cost of not considering the diversity on the objective space.
%
In some way this method was designed in an opposite way than current methods: the diversity
on variable space is considered but at the cost of disregarding the information of the diversity
on objective space.
%
The performance of \NSGA{} is not even close to current \MOEAS{} and one 
of the reason is precisely not considering the diversity on objective space.

In 2003, the \GDEA{}~\cite{toffolo2003genetic} proposed by Toffolo and Benini integrated the diversity into the search 
as an additional objective, which modifies the ranking of the indiviuals and favors maintaining distant indidivuals
during the whole optimization process.
%
In 2005, Chan and Ray \cite{chan2005evolutionary} proposed the application of selection operators to
encorage the preservation of distant solutions both in objective and decision space.
%
%They implemented \KPone{} and \KPtwo{}, two algorithms using these two selection operators.
%
Later, Deb and Tiwari proposed the Omni-optimizer~\cite{deb2008omni}.
%
This algorithm is designed as a generic multi-objective, multi-optima optimizer. %  , which extends the original idea of the \NSGA{}.
%
In the multi-objective case it is an extension of \NSGAII{} where the crowding distance considers both the objective and variable space.
%
Since it first uses the typical rank procedure considering only the objective space, more importance is given to this space. 
and the diversity plays an inferior role.
%
Unfortunately, there is no way to easily alter the importance given to each space.
%
In 2009, Shir et al. showed that the diversity in the decision variable space can be significantly enhanced without hampering 
the convergence to a diverse Pareto-front approximation.
%
Following this insight, the \CMAES{} niching framework was proposed~\cite{shir2009enhancing}.
%
Estimation of Distribution Algorithms have also considered the information of the decision space
to attain better aproximations of the Pareto set~\cite{zhou2009approximating}.
%
Finally, the Diversity Integrating Hypervolume-based Search Algorithm (\DIVA{})~\cite{ulrich2010integrating}
weights the hypervolume contribution with the diversity of the decision variable space.

Note that from the discussed methods the only one that shows some improvements in terms of objective-space metrics is \GDEA{}.
%
However, results attained by \GDEA{} are not as competitive as the ones attained by modern solvers so it is not currently
considered as an state-of-the-art \MOEA{} but as an easily applicable and general approach.
%
The rest of the methods focuses on showing that solutions with a higher level of diversiy on the variable space
can be obtained without a too negative effect
on the approximation of the Pareto Front.


\subsection{Multi-objective State-of-the-art Algorithms}

Given the large amount of \MOEAS{} proposed in the last decades, several taxonomies have been defined~\cite{bechikh2016recent}.
%
Most current techniques consider in some way at least one of the following concepts~\cite{trivedi2016survey}:
Pareto dominance, indicators and/or decomposition.
%
Note that several \MOEAS{} use more that one of these principles but most practitioners make the effort to classify
proposals as domination-based, indicator-based or decomposition-based.

In domination-based \MOEAS{}, the Pareto dominance relation is applied to bias the decisions of the optimizer.
%
Although this relation stimulates convergence to the Pareto front, additional techniques to promote
diversity in the objective space must be integrated.
%
Several of the most traditional \MOEAS{} belong to this group, and while they face some difficulties for many-objective
optimization, they are considered quite effective for optimization problems with two and three objectives.
%
Non-Dominated Sorting Genetic Algorithm-II (\NSGAII{}) is the most popular technique belonging to this group~\cite{deb2002fast}.
%
\NSGAIII{}~\cite{deb2013evolutionary} extends \NSGAII{} by replacing the crowing selection with an strategy 
based on generating distributed reference points that implicitly descompose the objective space~\cite{trivedi2016survey}.
%
While this method is aimed at many-objective optimization, it also provides some benefits for problems with three objectives.

Indicator-based \MOEAS{} incorporate a measure of quality over sets of solutions to alter some components such as the 
selection and/or replacement~\cite{beume2007sms}.
%
Indicators take into account both the convergence and coverage, so no additional techniques to promove diversity
in the objective space are required.
%
A quite effective \MOEA{} that belongs to this category is the R2-Indicator-Based Evolutionary Multi-objective 
Algorithm (\RMOEA{})~\cite{trautmann2013r2}.
%
\textsc{sms-emoa}~\cite{Joel:SMSEMOA} is also quite effective 
but it uses the computationally expensive hypervolume indicator, meaning that it is not so generally applicable as \RMOEA{}.

Finally, decomposition-based \MOEAS{}~\cite{ishibuchi1998multi} incorporate scalarizing functions to transform the \MOP{} 
into several single-objective optimization sub-problems.
%
Those sub-problems are then solved in a simultaneously and colaborative way.
%
The weighted Tchebycheff scalarizing approach have shown a remarkable performance.
%
The most popular \MOEA{} that belongs to this category is \MOEAD{}, which was proposed by Zhang et al.~\cite{zhang2007moea}.
%
A distinctive feature of the \MOEAD{} is the application of neighborhoods at the level of each sub-problem.
%
The mating selection and replacement operator takes into account this neighborhood to promote collaboration
between similar subproblems.
%
\MOEAD{} has gained a significant popularity in the last decade, so many extensions have been devised.
%
Particularly, the \MOEADDE{}~\cite{li2009multiobjective} --- winner of some optimization competitions --- provides
important advances by incorporating \DE{} operators, polynomial mutation, a dynamic computational resource allocation strategy, 
mating restrictions and a modified replacement operator to prevent the excessive replication of individuals. 

Since practitioners compare algorithms under different conditions, it is not easy to clearly identify the most effective ones.
%
Given the complementary properties contributed by the different discussed methodologies, our comparisons include \MOEAS{} belonging
to each category. Particularly, \NSGAII{}, \NSGAIII{}, \RMOEA{} and \MOEADDE{} are the set of state-of-the-art algorithms used
to validate our proposal.
