The concept of designing a \MOEA{} to manage the diversity in the decision variable space is not enterally new.
%
Specifically, in the literature can be found a few quantinty of \MOEAS{} that directly impose mechanisms to keep diversity in the decision variable space.
%
The majority of those algorithms are usually built to deal with a specific sort of \MOPS{} where each efficient point of the objective space corresponds to more than one Pareto-optimal solution in the decision variable space.
%
Therefore the algorithm should be able to find several Pareto-optimal solutions that corresponds to one efficient point~\cite{deb2008omni, cuate2019variation}.
%
In contrast, this work is particularly developed to deal with the habitual \MOPS{}, where the performance of a \MOEA{} is only measured in terms of its approximation quality in the objective space.
%

This section reviews the main works of diversity that motivates the design of the \VSDMOEAD{}.
%
Furthermore, the most popular \MOEAS{} that incorporates techniques that directly influences the diversity in the desicion variable space are listed.
%
Finally, a quite popular classification of \MOEAS{}, which is particularly employed for the habitual \MOPS{}, is described.

\subsection{Diversity in Single-objective Optimization}

The main theme of research on \EAS{} is to keep a balance between exploration and exploitation in its search~\cite{lin2009auto}.
%
A promising strategy to achieve this balance in single-objective optimization is to properly operate the diversity of the variable space.
%
This principle has encouraged the development of a vast quantinty of managment techniques~\cite{pandey2014comparative}.
%
A common classification of these methods depends on the sort of components modified in the \EA{}.
%
A popular taxonomy identifies the following groups~\cite{Joel:Crepinsek}: \textit{selection-based}, \textit{population-based}, \textit{crossover/mutation-based}, \textit{fitness-based}, and \textit{replacement-based}.
%
Similarly, other common classification defines two categories: \textit{uniprocess-driven} and \textit{multiprocess-driven}, whereas the former alters just one component, the latter simultaneously acts on more than one component.
%

%
In particular, the \textit{replacement-based} methods have yielded promising results in the last years~\cite{segura2016improving}.
%
The basic principle that governs this replacement operator is the modification of the level of exploration in successive generations by controlling the diversity of the survivors~\cite{segura2015novel}.
%
In this way, an adequate selection of diverse survivors might slow down the inconvenient of an accelerated convergence, which is quite common in \EAS{}.
%
One of the most popular proposals belonging to this group is the \textit{crowding} method, in which each new individual should replace similar individuals from the previous generation~\cite{mengshoel2014adaptive}.
%
For instance, a quite popular strategy is the \textit{Restricted Tournament Selection} (\RTS{})~\cite{harik1995finding}.
%
In \RTS{} each new individual randomly competes for a place with the $k$-nearest individuals of the population using the traditional binary tournament selection.
%
Several replacement strategies that do not rely on crowding have also been devised.
%
In some methods, diversity is considered as an objective.
%
For instance, in the hybrid genetic search with adaptive diversity control (\HGSADC{})~\cite{vidal2013hybrid}, individuals are sorted by their contribution to the diversity and by their original cost.
%
Then, the rankings of the individuals are used in the fitness assignment phase.
%
A more recent approach that has shown to be effective in a widely quantinty of problems incorporates a penalty approach to gradually alter the amount of diversity maintained in the population~\cite{segura2015novel, segura2016improving, castillo2019differential, angel2018explicit,romero2018memetic}.
%
Specifically, the initial phases explicitly preserve a higher amount of diversity than the final phases of the optimization.
%

Albeit that the last kind of methods can be incorporated to any category of \EA{}, Differential Evolution (\DE{}) has left its mark in themes regarding with methods that influences the convergece through diversity.
%
The main reason of this is that \DE{} is highly susceptible to the loss of diversity, which is mainly provoked by the greedy strategy applied in the selection phase~\cite{castillo2017multi}.
%
In fact, based in several theoretical and empirical studies~\cite{zaharie2003control, montgomery2009differential}, its parametrization influences the convergence quite aggressively.
%
Therefore, some analyses concludes that some kind of movements should be disallowed to delay the accelerated convergence~\cite{montgomery2009differential}.
%

For instance, a slight modification of \DE{} variates the kind of accepted movements along the run~\cite{montgomery2012simple}.
%
The latter is achieved, discarding movements with a norm below a threshold which is decreased as the genereations elapse.
%
This work ilustrates an importan point; the amount of diversity promoted should depend of the stopping criteria.
%
In this way --under certain conditions-- might be possible to achieve a balance along the execution~\cite{chen2015review, piad2015evolution}.
%
However, those methods do not consider explicitly the differences among the whole population.
%
Instead, mating restrictions are individually applied regarding each mutation taking place in the reproduction phase, therefore it just slows down the convergence of \DE{}.
%
Finally, a quite effective proposal \textit{Auto-Enhanced Population Diversity} (\AEPD{}) mesuares the diversity of each variable explicitly, then it triggers a mechanism to diversify the population each time that a low diversity degree is detected~\cite{yang2014differential}.
%

Recently, a new \DE{} variant has been proposed~\cite{castillo2019differential}.
%
This variant incorporates a replacement phase, which explicitly preserves diversity in several stages among the execution.
%
In this way, a dynamic balance between exploration and exploitation is carried out with the aim of adapting the optimizer to the requirements of the different optimization stages.
%
This last method has inspired the design of the novel proposal put forth in this paper for multi-objective optimization.


\subsection{Diversity in Multi-objective Optimization}\label{MOEAs:Diversity}

In spite of the vast quantinty of proposed \MOEAS{} few algorithms involves techniques that directly manage the diversity in the decision variable space.
%
In contrast to single-objective optimization where the promotion of diversity takes a straight role, in multi-objective optimization the diversity in the decision variable space usually is not explicitly attended.
%
The main reason is that the relation between the diversity of the objective space and the decision variable space is different in each \MOP{}~\cite{shir2009enhancing}.
%
In the habitual \MOPS{}, this relation maintain an implicit diversity degree in the decision variable space, which might represent one or more optimal regions.
%
Therefore, imposing a high level of diversity in the decision variable space might affect the convergence and/or spread of the Pareto-front approximation.
%


Particularly, a simple \EA{} tends to lose their population diversity during the search process~\cite{mahfoud1995niching}.
%
This drawback might be provoked by several reasons, such as genetic drift, fast takeover, and disruptive recombination~\cite{preuss2005counteracting}.
%
To alliviate those problems, the niching techniques, which promote the maintenance of stable sub-populations, were proposed.
%
The Non-Dominated Sorting Genetic Algorithm (\NSGA{}) developed in 1995~\cite{srinivas1994muiltiobjective} was one of the first \MOEAS{} that employes the fitness sharing which is classified as a niche techinque.
%
This \MOEA{} incorporates the non-dominated sorting procedure and the fitness sharing.
%
The latter is directly applied in the decision variable space with the intention of maintain a diverse population.
%

In 2003, the \GDEA{}~\cite{toffolo2003genetic} proposed by Toffolo and Benini integrated the diversity into the search as an additional objective.
%
Specifically, this \MOEA{} invokes two selection criteria: the non-dominated sorting and a diversity metric.
%
In 2005, Chan and Ray \cite{chan2005evolutionary} suggested the incorporation of two selection operators in \MOEAS{}; one encourages the diversity in the objective space and the other does so in the decision space.
%
They implemented \KPone{} and \KPtwo{}, two algorithms using these two selection operators.
%
Three years later, Deb and Tiwari proposed the Omni-optimizer~\cite{deb2008omni}.
%
This algorithm is designed as a generic multi-objective, multi-optima optimizer, which extends the original idea of the \NSGA{}.
%
Principally, the diversity measures are taken in both spaces, thus Omni-optimizer first uses a rank procedure that first analyze the objective space and secondly the decision variable space.
%
However, the drawback of this approach is that the diversity plays an inferior role and there is no possibility to change the tradeoff between the diversity measures.
%

In 2009, Shir et al. demostrated that the diversity in the decision variable space can be significantly enhanced without hampering the convergence to a diverse Pareto-front approximation, following this point the \CMAES{} niching framework was proposed~\cite{shir2009enhancing}.
%
In the same year Zhou et al. proposed a probabilistic Model-based Multi-objective Evolutionary Algorithm (\MMEA{})\cite{zhou2009approximating}.
%
This algorithm applies a clustering procedure in objective space to build a model.
%
In 2010, was proposed the Diversity Integrating Hypervolume-based Search Algorithm (\DIVA{}) \cite{ulrich2010integrating}.
%
This algorithm weights the hypervolume indicator contribution with the diversity of the decision variable space.


\subsection{Multi-objective Classification}


In the last decades the \MOEAS{} have gained enough popularity dealing with \MOPS{} and given their outstanding performance a vast amount of variants have been proposed.
%
To better classify the different schemes, several taxonomies have been defined~\cite{bechikh2016recent}.
%
A well known and acceptable classification is based on Pareto dominance, indicators and/or decomposition~\cite{trivedi2016survey}.
%
%Nevertheless, some recent \MOEAS{} might involve a mixture of several components, e.g. the \NSGAIII{} integrates weight vectors.


The domination-based \MOEAS{} are mainly designed with the application of the Pareto dominance relation.
%
Although this relation stimulates the convergence to the Pareto front, incorporating only this concept steers to the convergence of a Pareto optimal sub-region.
%
Therefore, those algorithms also integrate techniques to promote the diversity in the objective space.
%
%
%However, In spite that the simplicity and efficiency of this sort of \MOEAS{} is evident in multi-objective optimization.
%
In spite of its simplicity and efficiency this kind of \MOEAS{} face difficulties converging to the Pareto front in many-objective optimization problems.
%
A quite popular \MOEA{} that belongs to this category is the Non-Dominated Sorting Genetic Algorithm-II (\NSGAII{})~\cite{deb2002fast}.
%
The indicator-based \MOEAS{} incorporate a measure of quality of the approximations attained by the \MOEAS{}~\cite{beume2007sms}.
%
In contrast to the dominance-based \MOEAS{}, this measure of quality represents the convergence and coverage.
%
A quite popular \MOEA{} that belongs to this category is the R2-Indicator-Based Evolutionary Multi-objective Algorithm (\RMOEA{})~\cite{trautmann2013r2}.
%
Finally, the decomposition-based \MOEAS{} incorporate scalarizing functions to transform the \MOP{} into several single-objective optimization sub-problems.
%
Those sub-problems are solved in a simultaneously and colaborative way among the run.
%
Some of the most common scalarizing functions that are applied to transform the \MOP{} are the weighted sum approach, the weighted Tchebycheff approach and the penalty-based boundary intersection approach.
%
Particularly, each scalarizing function has its own properties that in combination with a weight vector define a single-objective function.
%
Those functions aim the search to a Pareto front region, which is implicitly outlined by a weight vector.
%
Therefore, the \MOEA{} optimizes several single-objective functions through a set of weight vectors.
%
Those weight vectors are selected with the intention of obtaining converged and well-spread solutions among the Pareto front.
%
However, the best distribution of weight vectors regards to each \MOP{} and its Pareto-greometry.
%
A popular \MOEA{} that belongs to this category is the \MOEAD{} proposed by Zhang et al.~\cite{zhang2007moea}.


The \MOEAD{} is frequently considered as the starting point in the history of the based-decomposition algorithms.
%
Nevertheless, in the literature stands out several antecedents of metaheuristics that deal with \MOPS{} funded in the idea of decomposition~\cite{ishibuchi1998multi, murata2002cellular}.
%
Particularly, the \MOEAD{} has its origins in the Cellular Multi-objective Genetic Algorithm (\CMOEA{}) proposed by Murata and Gen~\cite{murata2002cellular}.
%
A distinctive feature of the \MOEAD{} is the definition of neighborhoods.
%
Then, each sub-problem defines a neighborhood through the other $k$-nearest sub-problems.
%
The association is taken in terms of the Euclidean distance between the weight vectors.
%
In this way the \MOEAD{} incorporates a mating selection and a replacement operator through its neighborhoods.
%
Such features influence the quantinty of diversity that is preserved in the population.
%
For instance, a solution that has converged quite well could replace several non-converged solutions in its neighborhood, provoking a drastic deterioration of the diversity~\cite{wang2015constrained}.
%
To alliviate the previous shortcommings and to stablish some improvements Li and Zhang proposed the \MOEADDE{}~\cite{li2009multiobjective}.
%
The main modifications imposed in the \MOEADDE{} are the incorporation of \DE{} operators, a computational resource allocation strategy, mating restrictions and the replacement operator.
%
Initially, the \MOEADDE{} incorporates the \DE{} in combination with the polynomial mutation, droping out the \SBX{}-crossover  employed in the antecesor \MOEAD{}.
%
Additionally, in the \MOEAD{} all the sub-problems are treated equally reciving the same computational effort by each generation, however in some scenarios some sub-problems might converge faster than the remaining ones.
%
To alliviate this the \MOEADDE{} employes a computational resource allocation strategy which grants different computational effort to each sub-problem which is based in its performance.
%
Finally, in the replacement operator of the \MOEAD{} a solutions might be replicated excessively.
%
Therefore, the \MOEADDE{} limits the number of times that a child solution can be assigned to its neighborhood, which avoids an excessive number of copies.
%
In spite of the modifications imposed to the \MOEADDE{}, is important to remark that the incorporation of such techniques just delays the convergence, and does not have mechanisms to avoid stagnation or premature convergence.
%
