This section is devoted to carry out the validation of our proposal against state-of-the-art \MOEAS{}.
%
Particularly, is shown that controlling the diversity of the decision variables can be benefical to attain better approximations to the Pareto front.
%
The latter is proven employing long-term executions with some of the most popular \MOEAS{}.
%
Although that this principle can be incorporated into any multi-objective paradigm, the benefits of promoting diversity are only confirmed with a decomposition-based algorithm.
%
To have a clear insight of the performance of each selected algorithm, this section is arranged as follows.
%
At first, the technical parameterization that governs the common comparison is presented.
%
Then, a quite common and representative comparison between all the \MOEAS{} in long-term executions is shown.
%
In order, to have a better understanding of the scalability and stability, three more experiments are driven.
%
These experiments are designed to test the scalability of the decision variables, analyze the impact of diversity among the execution, and robustness of \VSDMOEAD{} with different initial penalty thresholds.
%
The latter seeks to illustrate the effects of promoting diversity with different initial levels.
%

The validation of the \MOEAS{} takes into account three of the most popular benchmarks in multi-objective optimization.
%
These problems are the \WFG{}~\cite{huband2006review}, \DTLZ{}~\cite{deb2005scalable}, and \UF{}~\cite{zhang2008multiobjective}, whose selected configuration is taken from the literature.
%
Specifically, the \WFG{} test problems were used with two and three objectives configured with $24$ parameters\footnote{In the \WFG{} context the term \textit{parameters} is equivalent to variables.}, $20$ of them corresponding to distance parameters and $4$ to position parameters.
%
In the \DTLZ{} test problems, the number of variables was set to $n=M+r-1$, where $r=\{5, 10, 20\}$ for DTLZ1, DTLZ2 to DTLZ6 and DTLZ7, respectively.
% 
The \UF{} benchmark comprises seven problems with two objectives (\UF{}1-7) and three problems with three objectives (\UF{}8-10).
%
This last set of problems were configured with $30$ variables.
%

The state-of-the-art \MOEAS{} that are taken into account are four of the most popular in multi-objective optimization.
%
Those algorithms are \NSGAII{}~\cite{deb2002fast}, \MOEADDE{}~\cite{zhang2009performance}, \RMOEA{}~\cite{trautmann2013r2} and \NSGAIII{}~\cite{deb2013evolutionary}.
%
While the former three can be classified as dominance-based, decomposition-based and indicator-based, the latter might be considered as an hybrid, since that it introduces the main framework of \NSGAII{} and utilizes a set of weight vectors as reference points~\cite{trivedi2016survey}.
%
In a similar way than some of the most popular \MOEAS{}, \MOEAD{} has been taken as a representative based-decomposition algorithm, which has inspired the development a vast quantity of algorithms in its category.
%
Particularly, in this analyses is included the \MOEADDE{}, which obtained the first place in the Congress on Evolutionary Computation 2009 (\CEC{}-2009)~\cite{zhang2009performance}.
%

Each experiment that was run in this section is configured with a population size of $100$ individuals.
%
Moreover, the variation operators integrated in all the \MOEAS{} is the classic binomial \DE{} scheme better known as DE/rand/1/bin.
%
In addition, \MOEAD{} and \VSDMOEAD{} incorporate the polynomial mutation with probability and distribuion index fixed to $1/n$ and $50$, respectively.
%
To have a fair comparison, for each \MOEA{} the crossover probability ($CR$) and mutation factor ($F$) values were chosen by grid-search.
%
Particularly, we have tested $20$ combinations of four values of $F$ (i.e. 0.25, 0.5, 0.75 and 1.0) and five values of $CR$ (i.e. 0.0, 0.25, 0.5, 0.75, 1.0) with two and three objectives.
%
The performance of each combination was measured taking into account the whole set of problems and a stopping criterion of  $2.5 \times 10^{6}$ function evaluations.
%
In this way each \MOEA{} was set with the values whose performance was the best, such values are reported in Table~\ref{tab:tunning}. Note that a detailed information can be found in the supplementary material.
%

%
The specific parameterization required by each algorithm is shown in Table~\ref{tab:Parametrization}.
%
Note that scalarization functions are required in \MOEADDE{}, \RMOEA{}, \NSGAIII{} and \VSDMOEAD{}.
%
In all those cases, the \ASF{} approach is used.
%
Nevertheless, the weight vectors employed in \RMOEA{} are distinct that in the remaining algorithms.
%
According to the author's code, \RMOEA{} was applied with $501$ and $496$ weight vectors for two and three objectives, respectively~\cite{trautmann2013r2}.
%
In contrast, to have the same quantity of weight vectors than the population size, the remaining algorithms incorporate a different distribution of weight vectors.
%
Those weight vectors were generated with the Uniform Design (\UD{}) and the Good Lattice Point (\GLP{}) method~\cite{tan2013moea1, tan2013moea2}.
%
Given that all the algorithms are stochastic, each execution was repeated $35$ times with different seeds.
%
The hypervolume indicator (\HV{}) is used to compare the various schemes.
%
The reference point used to calculate the \HV{} is chosen to be a vector whose values are sightly larger (ten percent) than the nadir point, as suggested in~\cite{ishibuchi2017reference}.
%
The normalized \HV{} is used to facilitate the interpretation of the results~\cite{li2014evolutionary}, and the value reported is computed as the ratio between the normalized \HV{} obtained and the maximum attainable normalized \HV{}.
%
In this way, a value equal to one means a perfect approximation.
%
Note that such value is not attainable because \MOEAS{} yields a discrete approximation.
%

Finally, to statistically compare the \HV{} ratios, a guideline similar to that proposed in~\cite{durillo2010study} was used.
%
First a Shapiro-Wilk test was performed to check if the values of the results followed a Gaussian distribution.
%
If so, the Levene test was used to check for the homogeneity of the variances.
%
If the samples had equal variance, an ANOVA test was done; if not, a Welch test was performed.
%
For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution.
%
An algorithm $X$ is said to beat algorithm $Y$ when the differences between them are statistically significant, and the mean and median \HV{} ratios
obtained by $X$ are higher than the mean and median achieved by $Y$.


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[t]
\centering
\caption{\DE{} parameterizaon applied to each \MOEA{}}
\label{tab:tunning}
%\resizebox{\textwidth}{!}{%
\begin{tabular}{c|c|c|c|c}
\hline
\multirow{2}{*}{}   & \multicolumn{2}{c|}{\textbf{2 objectives}} & \multicolumn{2}{c}{\textbf{3 objectives}} \\ \cline{2-5} 
                    & $CR$                 & $F$                 & $CR$                 & $F$                 \\ \hline
\textbf{AVSD-MOEA/D} & 0.0                  & 0.75                & 0.0                  & 0.75                \\ \hline
\textbf{MOEA/D-DE}  & 0.75                 & 0.75                & 0.5                  & 0.5                 \\ \hline
\textbf{R2-EMOA}    & 0.75                 & 0.5                 & 0.5                  & 0.5                 \\ \hline
\textbf{NSGA-II}    & 0.75                 & 0.5                 & 0.0                  & 0.25                 \\ \hline
\textbf{NSGA-III}   & 0.75                  & 0.25                 & 0.0                  & 0.75                 \\ \hline
\end{tabular}%
%}
\end{table}

\begin{table}[t]
\centering
\caption{ Parameterization applied to each MOEA}
\label{tab:Parametrization}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{
\textbf{MOEA/D-DE}} & Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 20, \\
 & period utility updating = 50 generations, \\
 & local selection probability ($\delta$) = 0.9,\\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\textbf{AVSD-MOEA/D} & $D_I=0.4$ \\ \hline
\end{tabular}
\end{table}



\subsection{Performance of \MOEAS{} in long-term executions}


A critical point of our proposal is to yield even better approximations extending the stopping criterion.
%
Keeping this in mind, our comparisons are carried out with long-term executions.
%
Therefore, in this section the stopping criterion was set at $2.5 \times 10^7$ function evaluations.
%

%
Table~\ref{tab:StatisticsHV_2obj} shows the \HV{} ratio obtained for the benchmark functions with two objectives.
%
For each method and problem is reported the best, mean and standard deviation of the \HV{} ratio values.
%
Furthermore, to summarize each method, the last row shows the results considering the whole set of problems.
%
For each test problem, the method that yielded the largest mean and those that were not statistically inferior than the best are shown in \textbf{boldface}.
%
%Additionally, all the methods that were not statistically inferior than the method with the largest mean are shown in \textbf{boldface}.
%
Similarly, the method that yielded the best \HV{} values among all the runs are {\ul underlined}.
%
From here on, the methods shown in {\bf boldface} for a given problem are referred to as the winning methods.
%

The rank of the methods based on the wins is \VSDMOEAD{}, \RMOEA{}, \NSGAIII{}, \MOEADDE{} and \NSGAII{}, whose counts are $15$, $7$, $5$, $5$ and $2$, respectively.
%
This indicates that \VSDMOEAD{} is the winner, in fact it won more than twice times than the method in second place (\RMOEA{}).
%
This superiority is confirmed with the \HV{} ratio value considering the whole set of problems.
%
In contrast, \RMOEA{} attained the worst value of $0.897$, this might occurs since some problems were not approximated properly reporting a remarkably degradation of the \HV{} ratio.
%
In spite that the decomposition-based \MOEAS{} achieved the highest mean \HV{} ratio values, the difference reported by \VSDMOEAD{} ($0.973$) is considerably greater than \MOEADDE{} ($0.931$).
%
Inspecting the data carefully, it can be seen that in the case where \VSDMOEAD{} loses, the difference with respect to the best method is not very large.
%
For instance, the difference between the mean \HV{} ratio attained by the best method and by \VSDMOEAD{} was never larger than $0.1$.
%
However, all the other methods exhibited a deterioration greater than $0.1$ in several cases.
%
Specifically, it happened in $5$, $4$, $5$ and $4$ problems for \RMOEA{}, \NSGAII{}, \NSGAIII{} and \MOEADDE{}, respectively.
%
Similar conclusions can be drawn analyzing the standard deviation.
%
This means that even if \VSDMOEAD{} loses in some cases, its deterioration and standard deviation is always small, exhibiting a much more robust behavior than any other method.


In order to better clarify these findings, pair-wise statistical tests were done among each method tested in each test problem.
%
For the two-objective cases, Table~\ref{tab:Tests_HV_2obj} shows the number of times that each method statistically won (column $\uparrow$), lost (column $\downarrow$), tied (column $\leftrightarrow$) and a metric of \textbf{Score}.
%
The latter indicates the difference between the number of times that each method won and the number of times that each method lost.

%
Additionally, for each method $M$, we calculated the sum of the differences between the mean \HV{} ratio attained by the best method (the ones with the highest mean) and method $M$, for each problem where $M$ was not in the group of winning methods.
%
This value is shown in the Deterioration column.
%
The data confirms that although \VSDMOEAD{} loses in some cases, the overall numbers of wins and losses favors \VSDMOEAD{}.
%
More importantly, the total deterioration is quite lower in the case of \VSDMOEAD{}, confirming that when \VSDMOEAD{} loses, the deterioration is not that large.

Tables~\ref{tab:StatisticsHV_3obj} and~\ref{tab:Tests_HV_3obj} show the same information for the problems with three objectives.
%
In this case the rank of the methods based on the wins is \VSDMOEAD{}, \RMOEA{}, \MOEADDE{}, \NSGAIII{} and \NSGAII{}, whose counts are $9$, $9$, $3$, $2$ and $0$, respectively.
%
%In spite that \VSDMOEAD{} and \RMOEA{} won with a same number of problems, \VSDMOEAD{} again obtained a much larger mean \HV{} ratio than the \RMOEA{} ($0.912$ vs. $0.866$).
%
Taking into account the mean of all the test problems, \VSDMOEAD{} again obtained a much larger mean \HV{} ratio than the remaining ones.
%
Once again, the difference between the mean \HV{} ratio obtained by the best method and by \VSDMOEAD{} was never greater than $0.1$.
%
However, all the other methods exhibited a deterioration greater than $0.1$ in several cases.
%
In particular, this happened in $3$, $6$, $4$ and $2$ problems for \RMOEA{}, \NSGAII{}, \NSGAIII{} and \MOEADDE{}, respectively.
%
In spite that \VSDMOEAD{} is superior than the other methods in terms of total deterioration, its pair-wise statistical tests are not remarkably superior than \RMOEA{} in terms of total wins and losses (see Table~\ref{tab:Tests_HV_3obj} and data shown in {\bf boldface} in Table~\ref{tab:StatisticsHV_3obj}).
%
This might occurs since that \RMOEA{} takes into account a greater number of weight vectors, in some problems it allows the allocation of solutions in regions that contributes in a better way to \HV{}.
%
Nevertheless, the mean \HV{} ratio value attained by \VSDMOEAD{} is quite superior than the remaining methods.
%
In fact the \HV{} ratio values attained by \VSDMOEAD{} in each problem is not worst than the reported by \MOEADDE{} and \NSGAIII{} with three objectives, such methods incorporated the same number of weight vectors.
%
To prove those arguments, in the supplementary material is shown a variant of our proposal \AVSDMOEAD{} in which is incorporated an external archive based in the \RR{} indicator.
%
\AVSDMOEAD{} was remarkable superior than the state-of-the-art \MOEAS{} with two and three objectives in both total deterioration ($0.153$ and $0.006$) and term of total wins and loses ($80$ and $73$ wins).
%
%Although that the performance of \VSDMOEAD{} can be affected by the distribution of the weight vectors, its overall \HV{} ratio values are quite better.
%



\input{tablas/Table_HV_2obj.tex}
\input{tablas/Tests_HV_2obj.tex}

\input{tablas/Table_HV_3obj.tex}
\input{tablas/Tests_HV_3obj.tex}


\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_WFG1-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_WFG1-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diverstiy of distance variables (first row) and mean of \HV{} values (second row) vs. elapsed time in the bi-objective WFG1 test problem. The reported results are taken from $35$ runs.}\label{fig:WFG1_Diversity}
\end{figure}


\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_UF5-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_UF5-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diverstiy of distance variables (first row) and mean of \HV{} values (second row) vs. elapsed time in the bi-objective UF5 test problem. The reported results are taken from $35$ runs.}\label{fig:UF5_Diversity}
\end{figure}

In order to better understand the benefits of \VSDMOEAD{} against the state-of-the-art \MOEAS{}.
%
This section ilustrates the evolution of the \HV{} values and the diversity of some \MOPS{}.
%
According to the \WFG{} test problems, the variables can be classified into two kinds of variables: the distance variables and the position variables.
%
Note that a variable $x_i$ is a distance variable when for all $x$, modifying $x_i$ results in a new solution that dominates $x$, is equivalent to $x$, or is dominated by $x$.
%
However, if $x_i$ is a position variable, modifying $x_i$ in $x$ always results in a vector that is incomparable or equivalent to $x$~\cite{huband2006review}.
%
Particularly, in the WFG1 the distance variables are uni-modal and its optimal region has polynomial and flat properties, which might provoke stagnation in some \MOEAS{}.
%
In contrast, the UF5 is a multi-modal problem and its optimal regions are quite isolated among the decision variable space, in fact its Pareto optimal front is discretized and conformed by only $21$ points.
%
%
For each algorithm, the selected diversity metric is calculated as the average Euclidean distance among individuals (\ADI{}) in the population by considering only the distance variables.
%
Figures~\ref{fig:WFG1_Diversity} and~\ref{fig:UF5_Diversity} show how the ADI (top) and the mean of \HV{} (bottom) evolve for the WFG1 and UF5, respectively.
%
In the WFG1 problem, the distance variables of the state-of-the-art \MOEAS{} converged to a region approximately after the $10\%$ of the total execution.
%
Among the remaining function evaluations those \MOEAS{} were not able to improve the quality of its approximations.
%
In the case of \VSDMOEAD{}, the decrease in \ADI{} is quite linear until the halfway point of the execution.
%
Showing that preserving diversity at different levels might improve the final approximation.
%
Although \RMOEA{} attained the best \HV{} values in several problems, its degradation in some problems (e.g. WFG1) is quite shocking.
%
This is not the case of \VSDMOEAD{}, whose performance was always the best or almost the best.
%

Promoting explicitly diversity among the execution is also benefical to multi-modal problems.
%
For instance, the advantage of promoting diversity in the UF5 test problem is shown in Figure~\ref{fig:UF5_Diversity}.
%
Particularly, this figure shows that \VSDMOEAD{} not only attained a better \HV{} values at the first $10\%$ of total function evaluations, it also kept looking for promising regions.
%
In fact, its \HV{} values improved meaningfully until a half of total execution that is the final point in which the diversity were explicitly promoted.
%
It also shows that \MOEADDE{} finds several promising regions among the execution, such effect might be provoked by the polynomial mutation.
%
Nevertheless, the improvements provoked by this operator does not improve two state-of-the-art \MOEAS{} at the end of the execution.
%
The reamining \MOEAS{} reported the same \HV{} and \ADI{} values after $10\%$ of the total function evaluations.


\subsection{Decision Variable Scalability Analysis}

In order, to have a better insight of the benefits of our proposal, the scalability in term of the number of decision variables is tested.
%
In particular, this experiment was carried out with the decomposition-based algorithms.
%
Such \MOEAS{} were applied with the same benchmark problems, but considering $50$, $100$, $250$ and $500$ variables.
%
Note that in the WFG test problems, the number of position variables and distance variables must be specified.
%
Specifically, the number of distance variables was set to $42$, $84$, $210$ and $418$ when using $50$, $100$, $250$ and $500$ variables, respectively.
%
%The remaining variables were the position variables, whose number was set to $8$, $16$, $40$ and $82$, respectively.
The rest of the decision variables were position variables, meaning that they were $8$, $16$, $40$ and $82$, respectively.
%
In addition, the stopping criterion was set to $2.5 \times 10^7$ function evaluations.
%
Figures~\ref{fig:scalability-2obj} and~\ref{fig:scalability-3obj} show the mean \HV{} ratio for the selected algorithms, considering the problems with two and three objectives, respectively.
%
In spite that the \HV{} ratio decreases as the number of variables increases, with two and three objectives the performance of \VSDMOEAD{} is quite robust, in fact its deterioration is much lower than \MOEADDE{}.
%

\begin{figure}[t]
\centering
\includegraphics[scale=0.85]{images/Graphic-Scalability-2obj_tikz-figure0.eps}
\caption{Mean of the \HV{} ratio for 35 runs for the two-objective problems considering different numbers of variables}\label{fig:scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[scale=0.85]{images/Graphic-Scalability-3obj_tikz-figure0.eps}
\caption{Mean of the \HV{} ratio for 35 runs for the three-objective problems considering different numbers of variables} \label{fig:scalability-3obj}
\end{figure}


\begin{figure}[t]
\centering
\includegraphics[scale=0.85]{images/Graphic-Initial-Distance_tikz-figure0.eps} \\
\caption{Mean of \HV{} values taking into account all the problems with several initial threshold values}\label{fig:Initial-distance-factor}
\end{figure}


\subsection{Analysis of the Initial Threshold Value}

Possibly, the main downside of including a strategy to explicitly promoting the diversity is the need of incorporating an additional parameter.
%
For instance, \VSDMOEAD{} requires to set an initial threshold value ($D_I)$.
%
Given the evidence of several findings in the literature, in the previous experiments a value of $D_I=0.4$ was used.
%
However, in this section a more detailed study of this parameter is driven.
%

%
In this section is analized the overall performance of \VSDMOEAD{} using different $D_I$ values.
%
Thereafter, in a more specifically way, the effect of this parameter is analized in WFG9 and UF10 test problems, in two and three objectives, respectively.
%
Note that, since normalized distances are used, the maximum difference that can appear is $1.0$, which belongs to the main diagonal of the box-constrained minimization \MOP{}.
%
Additionally, note that when $D_I$ is set to $0.0$, no individual is penalized on the basis of its decision variable space diversity contribution, so \VSDMOEA{} would behave like a more traditional \MOEA{}.
%
Specifically, the values $D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\}$ were tested.
%
As in previous experiments, the whole set of benchmark problems was used and the stopping criterion was set to $2.5 \times 10^7$ function evaluations.

Figure~\ref{fig:Initial-distance-factor} shows the mean \HV{} ratio obtained for both the two-objective  and the three-objective case.
%

The worst performance of the \VSDMOEAD{} is when it is set to $D_I=0.0$.
%
The \HV{} ratio obtained quickly increases as higher $D_I$ values up to $0.2$ are used.
%
Larger values provide a quite similar performance.
%
In fact, there is a wide range of values (from $0.2$ to $1.0$) where the performance is very good, meaning that the behavior of \VSDMOEA{} is quite robust.
%
Thus, properly setting this parameter is not a complex task.
%

In the same way than in the previous experiments, the Figures~\ref{fig:WFG9_Diversity} and~\ref{fig:UF10_Diversity} show the evolution of diversity (top side) and \HV{} ratio (bottom side) among the execution.
%
The WFG9 test problem is multi-modal and deceptive.
%
In addition, the UF10 test problem is highly multi-frontal and can be considered as one of the most challenging problems.
%
Such diagrams belong to \VSDMOEAD{} with the values $D_I = \{0.0, 0.4, 1.0\}$.
%
Interestingly, the behavior of \VSDMOEAD{} with $D_I=0.0$ is quite similar than the state-of-the-art \MOEAS{}, which confirms or previous claim.
%
The motivation behind those diagrams is to ilustrate that to achieve a better balance between exploration and exploitation can be the explicit promotion of diversity among the execution.
%
Therefore, those figures show that in multi-objective optimization --depending in each \MOP{}-- there is a relation between the diversity and the quality solutions, in fact visually the shapes of the \ADI{} and \HV{} ratio complement each other.
%
Even more the \HV{} ratio values are constantly improving as the execution time elapses.
%

\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_WFG9-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_WFG9-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diverstiy of distance variables (first row) and mean of \HV{} values (second row) vs. elapsed time in the two-objective WFG9 test problem. The reported results are taken from $35$ runs.}\label{fig:WFG9_Diversity}
\end{figure}


\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_UF10-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.8]{images/Diversity_Long_Term_tikz_UF10-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diverstiy of distance variables (first row) and mean of \HV{} values (second row) vs. elapsed time in the three-objective UF10 test problem. The reported results are taken from $35$ runs.}\label{fig:UF10_Diversity}
\end{figure}

