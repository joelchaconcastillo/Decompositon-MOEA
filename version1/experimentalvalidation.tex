This section is devoted to show the validation of our proposal against state-of-the-art \MOEAS{} and
to explain the reasons behind the superiority of \AVSDMOEAD{}.
%
%Esto lo pasamos a las conclusiones
%Particularly, it is shown that controlling the diversity of the decision variables is benefical to attain better 
%approximations to the Pareto front.
%
Since methods including strategies to delay convergence in an explicit way usually require additional computational
resources to excel, analyses in the long-term are presented.
%
In order to attain proper conclusions, three experiments were carried out.
%
%First, the technical parameterization that governs the common comparison is presented.
First, a comparison between \AVSDMOEAD{} and four state-of-the-art \MOEAS{} is included.
%
This comparison focuses on showing the benefits of \AVSDMOEAD{} for benchmarks 
configured in standard ways.
%
Second, an analysis to test the scalability on the number of decision variables is carried out.
%
Finally, the robustness of \AVSDMOEAD{} in terms of the initial penalty threshold ($D_I$) is analyzed.
%
Note that in order to test the quality of the approximations, the hypervolume is used.
%
Additionally, our analyses also include some studies to better understand
the implications of \AVSDMOEAD{} for the diversity on variable space.
%
These analyses allow to better understand the reasons behind the proper performance of \AVSDMOEAD{}
and to highlight the significant differences between \AVSDMOEAD{} and other strategies in terms of the dynamics
of the population.



Our validation takes into account three of the most popular benchmarks in multi-objective optimization:
\WFG{}~\cite{huband2006review}, \DTLZ{}~\cite{deb2005scalable}, and \UF{}~\cite{zhang2008multiobjective}.
%
Except otherwise stated, they were configured in a standard way.
%
Specifically, the \WFG{} test problems were used with two and three objectives with $24$ 
parameters\footnote{In the \WFG{} context the term \textit{parameter} is equivalent to variable.}, 
$20$ of them corresponding to distance parameters and $4$ to position parameters.
%
The \DTLZ{} test problems were also used with two and three objectives and the number of variables in each
case was set to $D=M+r-1$, where $r=\{5, 10, 20\}$ for \DTLZ{}1, \DTLZ{}2 to \DTLZ{}6 and \DTLZ{}7, respectively.
% 
The \UF{} benchmark comprises seven problems with two objectives (\UF{}1-7) and three problems with three objectives (\UF{}8-10).
%
This last set of problems were configured with $30$ variables.

\begin{table}[t]
\centering
\caption{Parameterization of the variation phase applied in each \MOEA{}}
\label{tab:tunning}
%\resizebox{\textwidth}{!}{%
\begin{scriptsize}
\begin{tabular}{c|c|c|c|c}
\hline
\multirow{2}{*}{} &\multicolumn{2}{c|}{ \textbf{2 objectives} }& \multicolumn{2}{c}{\textbf{3 objectives} }\\ \cline{2-5} 
 & $CR$ & $F$ & $CR$ & $F$ \\ \hline
\textbf{AVSD-MOEA/D} & 0.0 & 0.75 & 0.0 & 0.75 \\ \hline
\textbf{MOEA/D-DE} & 0.75 & 0.75 & 0.5 & 0.5 \\ \hline
\textbf{R2-EMOA} & 0.75 & 0.5 & 0.5 & 0.5 \\ \hline
\textbf{NSGA-II} & 0.75 & 0.5 & 0.0 & 0.25 \\ \hline
\textbf{NSGA-III} & 0.75 & 0.25 & 0.5 & 0.75 \\ \hline
\end{tabular}%
\end{scriptsize}
%}
\end{table}

Regarding our comparisons, the set of state-of-the-art \MOEAS{} used to validate our proposals is comprised of four 
popular and complementary \MOEAS{}: \NSGAII{}~\cite{deb2002fast}, \MOEADDE{}~\cite{zhang2009performance}, \RMOEA{}~\cite{trautmann2013r2} 
and \NSGAIII{}~\cite{deb2013evolutionary}.
%
%
%Note that \MOEADDE{} is the variant of \MOEAD{} that obtained the first place in the Congress on Evolutionary 
%Computation 2009~\cite{zhang2009performance}, which is considered as a quite effective \MOEA{}.
%
Given that all the algorithms are stochastic, each execution was repeated $35$ times in all the experiments.
%
The hypervolume indicator (\HV{}) is used to compare the various schemes.
%
The reference point used to calculate the \HV{} is chosen to be a vector whose values are sightly larger (ten percent) 
than the nadir point, as suggested in~\cite{ishibuchi2017reference}.
%
The normalized \HV{} is used to facilitate the interpretation of the results~\cite{li2014evolutionary}, 
and the value reported is computed as the ratio between the normalized \HV{} obtained and the maximum attainable normalized \HV{}.
%
In this way, a value equal to one means a perfect approximation.
%
Note that such value is not attainable because \MOEAS{} yields discrete approximations.
%
Finally, to statistically compare the \HV{} ratios, a guideline similar to that proposed in~\cite{durillo2010study} was used, 
which implies the use of the Shapiro-Wilk, Levene, ANOVA, Welch and Kruskal-Wallis tests.
%
An algorithm $A1$ is said to beat an algorithm $A2$ when the differences between the attained HV ratios are statistically significant, 
and the mean and median \HV{} ratios obtained by $A1$ are higher than the mean and median achieved by $A2$.

%
%First a Shapiro-Wilk test was performed to check if the values of the results followed a Gaussian distribution.
%
%If so, the Levene test was used to check for the homogeneity of the variances.
%
%If the samples had equal variance, an ANOVA test was done; if not, a Welch test was performed.
%
%For non-Gaussian distributions, the non-parametric Kruskal-Wallis test was used to test whether samples are drawn from the same distribution.
%

An important step to perform fair comparisons is the parameterization of algorithms.
%
Note that the variation operators used in each algorithm in their original variants differ.
%
Using the original variation operators to perform comparisons is not fair and probably would offer more conclusions 
about the effectiveness of the operators than about the general framework proposed in each \MOEA{}.
%
However, there might also be a dependency between the general framework and the proper variation operators.
%
Thus, we decided to use a common simple framework for the variation step but allow different parameterization
for each algorithm.
%
Particularly, the variation phase first applies the classic \DE{} scheme known as DE/rand/1/bin with parameters $F$
and $CR$, and then it applies polynomial mutation with probability $p_m$
and distribution index equal to $50$.
%
Note that the use of the additional mutation in variants based on \MOEAD{} is quite important~\cite{zhang2009performance}.
%
The additional common parameter is the population size.
%
Since the hypervolume highly depends on the number of solutions used to approximate the Pareto front,
all \MOEAS{} were configured with a common population size equal to $100$ individuals.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}

In order to set the $CR$, $F$ and $p_m$ parameters, 40 parameterizations were tested for each algorithm.
%
They were generated by combining four values of $F$ (0.25, 0.5, 0.75 and 1.0), five values of $CR$ (0.0, 0.25, 0.5, 0.75, 1.0) 
and two values of $p_m$ (0.0, $1\over{D}$).
%
These configurations were executed by setting the stopping criterion to $2.5 \times 10^{6}$ function evaluations, 
with all the aforementioned benchmarks.
%
The mean of the attained hypervolume ratios were calculated independently for the problems with two and three objectives.
%
Then, in the following experiments the parameter configuration that attained the largest mean is used.
%
Table~\ref{tab:tunning} reports the configuration of $CR$ and $F$ selected for each \MOEA{}.
%
Note that all of them attained better results when enabling the mutation, so the benefits reported in~\cite{zhang2009performance}
also appeared for other \MOEAS{}.
%
Note that in the case of \AVSDMOEAD{}, $CR$ was set to 0 which reduces the strength of the perturbation performed
by \DE{}.
%
Since \AVSDMOEAD{} maintains a larger degree of diversity than other methods, low disruptive
operators seems to be more helpful.



Note also that there are some additional parameters that are specific of some of the \MOEAS{}.
%
They were set to typical values used in literature. 
%
Table~\ref{tab:Parametrization} shows this additional parameterization.
%
Note also that scalarization functions are used in \MOEADDE{}, \RMOEA{}, \NSGAIII{} and \AVSDMOEAD{}.
%
In all those cases, the \ASF{} approach is used.
%
However, the weight vectors employed in \RMOEA{} are distinct that in the remaining algorithms because in \RMOEA{} using
a larger number of weight vectors than the population size is beneficial.
%
As in the official code, \RMOEA{} was applied with $501$ and $496$ weight vectors for two and three objectives, 
respectively~\cite{trautmann2013r2}.
%
In the remaining cases --- including \AVSDMOEAD{} --- the number of weight vectors is equal to the population size and they were generated
with the Uniform Design (\UD{}) and the Good Lattice Point (\GLP{}) method~\cite{tan2013moea1, tan2013moea2}.
%
Note that in the case of \AVSDMOEAD{} a second set of weight vectors is considered for the external archive.
%
It considers the same weight vectors than \RMOEA{}.

\begin{table}[t]
\centering
\caption{Configuration of specific parameters of each MOEA}
\label{tab:Parametrization}
\begin{scriptsize}
\begin{tabular}{c|c}
\hline
\textbf{Algorithm} & \textbf{Configuration} \\ \hline
\multirow{3}{*}{
\textbf{MOEA/D-DE}} & Max. updates by sub-problem ($\eta_r$) = 2, \\
 & tour selection = 10,   neighbor size = 20, \\
 & period utility updating = 50 generations, \\
 & local selection probability ($\delta$) = 0.9\\ \hline
\textbf{R2-EMOA} & $\rho=1$, offspring by iteration = $1$ \\ \hline
\textbf{AVSD-MOEA/D} & $D_I=0.4$ \\ \hline
\end{tabular}
\end{scriptsize}
\end{table}

\input{tablas/Table_HV_2obj.tex}
\input{tablas/Tests_HV_2obj.tex}


% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}



\subsection{Performance of \MOEAS{} in long-term executions}


One of the aim behind the design of \AVSDMOEAD{} is to profit from long-term executions.
%
Therefore, in this section the results attained by the different algorithms is shown by setting 
the stopping criterion to $2.5 \times 10^7$ function evaluations.
%
Table~\ref{tab:StatisticsHV_2obj} shows the \HV{} ratios obtained for the benchmark functions with two objectives.
%
For each method and problem the best, mean and standard deviation of the \HV{} ratio values are reported.
%
Furthermore, in order to summarize the results attained by each method, the last row shows the mean considering the whole set 
of problems.
%
For each test problem, the method that yielded the largest mean and those that were not statistically inferior than the 
best are shown in \textbf{boldface}.
%
Similarly, the method that yielded the best \HV{} value among all the runs are {\ul underlined}.
%
From here on, the methods shown in {\bf boldface} for a given problem are referred to as the winning methods.
%
\AVSDMOEAD{}, \RMOEA{}, \MOEADDE{}, \NSGAIII{} and \NSGAII{} belonged to the winning methods in 
$17$, $6$, $2$, $2$ and $0$ problems, respectively.
%
The superiority of \AVSDMOEAD{} is clear both in terms of this metric and in terms of the mean \HV{}.
%
Particularly, \AVSDMOEAD{} attained a value equal to $0.976$, while all the remaining methods attained values between
$0.931$ and $0.937$.
%
Inspecting the data carefully, it can be checked that in the cases where \AVSDMOEAD{} loses, the difference with respect to the best 
method is low.
%
In fact, the difference between the mean \HV{} ratio attained by the best method and by \AVSDMOEAD{} was never larger than $0.1$.
%
However, in all the other methods there were several problems where the distance with respect to the best approach
were larger than $0.1$.
%
Specifically, it happened in $4$, $4$, $4$ and $5$ problems for \RMOEA{}, \MOEADDE{}, \NSGAII{} and \NSGAIII{} respectively.
%
This means that \AVSDMOEAD{} wins in most cases and that when it loses, its difference is always small.
%
Note also that in terms of standard deviation, \AVSDMOEAD{} attains much lower values than the rest of the algorithms, meaning that
it is quite robust.


In order to better clarify these findings, pair-wise statistical tests were done among each method tested in each test problem.
%
For the two-objective cases, Table~\ref{tab:Tests_HV_2obj} shows the number of times that each method statistically won 
(column~$\uparrow$), lost (column~$\downarrow$) or tied (column~$\leftrightarrow$).
%
The column \textbf{Score} shows the difference between the number of times that each method won and the number of times that each 
method lost.
%
Additionally, for each method $M$, we calculated the sum of the differences between the mean \HV{} ratio attained by the best method 
(the ones with the highest mean) and method $M$, for each problem where $M$ was not in the group of winning methods.
%
This value is shown in the \textit{Deterioration} column.
%
The data confirms that although \AVSDMOEAD{} loses in some pair-wise tests, the overall numbers of wins and 
losses clearly favors \AVSDMOEAD{}.
%
More importantly, the total deterioration is quite lower in the case of \AVSDMOEAD{}, confirming that when \AVSDMOEAD{} loses, 
the differences are low.

\input{tablas/Table_HV_3obj.tex}
\input{tablas/Tests_HV_3obj.tex}


Tables~\ref{tab:StatisticsHV_3obj} and~\ref{tab:Tests_HV_3obj} shows the same information for the problems with three objectives.
%
In this case the number of times that each method belonged to the winning groups are $17$, $2$, $0$, $0$ and $0$ 
for \AVSDMOEAD{}, \RMOEA{}, \MOEADDE{}, \NSGAIII{} and \NSGAII{}, respectively.
%
Thus, \AVSDMOEAD{} attained quite superior results.
%
Considering the whole set of problems, \AVSDMOEAD{} obtained a much larger mean \HV{} ratio than the remaining ones.
%
Moreover, the difference between the mean \HV{} ratio obtained by the best method and by \AVSDMOEAD{} was never greater than $0.1$.
%
However, all the other methods exhibited a deterioration greater than $0.1$ in several cases.
%
In particular, this happened in $2$, $2$, $2$ and $6$ problems for \MOEADDE{}, \RMOEA{}, \NSGAIII{} and \NSGAII{} respectively.
%
Remarkably, \AVSDMOEAD{} is quite superior in both the total deterioration and in the score generated from the pair-wise
statistical tests.
%
In fact, its deterioration considering the whole set of problems is just $0.006$.
%
Beating all the state of the art algorithms in a so large number of problem benchmarks is a quite important attainment that shows
the robustness of \AVSDMOEAD{}.
%This might occurs since that \RMOEA{} takes into account a greater number of weight vectors, in some problems it allows the allocation of solutions in regions that contributes in a better way to \HV{}.
%
%In addition, \AVSDMOEAD{} is also quite superior than the remaining methods in terms of the mean \HV{} ratio when considering the whole
%set of benchmark problems.
%
The attained results show that the superiority of \AVSDMOEAD{} is maintained and even increased when considering 
problems with three objective functions.
%
%In fact the \HV{} ratio values attained by \AVSDMOEAD{} in each problem is not worst than the reported by \MOEADDE{} and \NSGAIII{} 
%with three objectives, such methods incorporated the same number of weight vectors.
%
%Although that the performance of \VSDMOEAD{} can be affected by the distribution of the weight vectors, its overall \HV{} ratio values are quite better.
%
%To prove those arguments, in the supplementary material is shown a variant of our proposal \AVSDMOEAD{} in which is incorporated an external archive based in the \RR{} indicator.
%
%\AVSDMOEAD{} was remarkable superior than the state-of-the-art \MOEAS{} with two and three objectives in both total deterioration ($0.160$ and $0.006$) and term of total wins and loses ($78$ and $74$ wins).



\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_WFG5-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_WFG5-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diversity of distance variables (top) and mean of \HV{} values (bottom) vs. elapsed time in the bi-objective WFG5 test problem. The reported results are taken from $35$ runs.}\label{fig:WFG5_Diversity}
\end{figure}


\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_UF5-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_UF5-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diversity of distance variables (top) and mean of \HV{} values (bottom) vs. elapsed time in the bi-objective UF5 test problem. The reported results are taken from $35$ runs.}\label{fig:UF5_Diversity}
\end{figure}

In order to better understand the reasons behind the benefits of \AVSDMOEAD{} against the state-of-the-art \MOEAS{},
inspecting the evolution of the \HV{} values and the diversity is quite helpful.
%
Note that in some \MOPS{} variables can be classified into two kinds of variables: 
the distance variables and the position variables.
%
A variable $x_i$ is a distance variable when for all $x$, modifying $x_i$ results in a new solution 
that dominates $x$, is equivalent to $x$, or is dominated by $x$.
%
Differently, if $x_i$ is a position variable, modifying $x_i$ in $x$ always results in a vector that is 
incomparable or equivalent to $x$~\cite{huband2006review}.
%
This is important because in some cases, \MOEAS{} do not maintain a large enough diversity in the distance
variables~\cite{castillo2017multi}, so analyzing the trend of diversity on these kinds of variables is useful
to get insight about the dynamics of the population.

In order to show the behavior of the different schemes we selected WFG5 and UF5.
%
They are complementary in the sense that in the WFG5, all the Pareto solutions present constant 
values in the distant variables, whereas this is not the case in UF5.
%
Moreover, in the UF5 the optimal regions are isolated in the decision variable 
space, meaning that more diversity is required.
%
In fact its Pareto optimal front is discrete and consists of $21$ points.
%
For each algorithm, the diversity is calculated as the average Euclidean distance among individuals (\ADI{}) in the population 
by considering only the distance variables.
%
Figures~\ref{fig:WFG5_Diversity} and~\ref{fig:UF5_Diversity} show the evolution of the ADI (top) and the mean of \HV{} (bottom) 
for the WFG5 and UF5, respectively.
%
In the WFG5 problem, the distance variables quickly converged to a small region 
in state-of-the-art \MOEAS{}.
%
Thus, the differential evolution operator loses it exploration power and as a result,
those \MOEAS{} were not able to improve the quality of its approximations significantly as the
evolution progresses.
%
Differently, in the case of \AVSDMOEAD{} the decrease in \ADI{} is quite linear until the midpoint of the execution and
the increase of \HV{} is gradual.
%
The final \HV{} attained by \AVSDMOEAD{} is the largest one which shows the important benefit
of the gradual decrease of diversity.

As expected, promoting diversity in an explicit way is also beneficial for problems with disconnected optimal regions.
%
Attending to the data shown in Figure~\ref{fig:UF5_Diversity}, the advantage of promoting diversity in the UF5 test 
problem is clear.
%
In this case, most state-of-the-art algorithms maintain some degree of diversity in the distance variables for
the whole search.
%
However, a large degree of diversity is required to reach the 21 optimal solutions and these \MOEAS{} do not maintain
the required amount of diversity, meaning that many of the solutions are not attained.
%
In the case of \AVSDMOEAD{} the enforcement of a large degree of diversity at initial phases, promotes a larger exploration 
that enables finding additional optimal regions.
%
Once this regions are located, they are not discarded meaning that a larger level of diversity is maintained for the whole
execution.
%
This way, \AVSDMOEAD{} not only attained better \HV{} values at the first $10\%$ of total function evaluations, but 
it also kept looking for promising regions.
%
In fact, its \HV{} values improved significantly until the midpoint of the execution period i.e., the final moment
in which the diversity was explicitly promoted.
%
Then, some additional increase was attained due to the intensification in the located regions.
%
This analysis shows that the dynamics of the population depends on the problem at hand.
%
The behavior of \AVSDMOEAD{} for problems where there is a distinction between distance and position variables 
were similar to those already presented.
%
Cases where the optimal regions consists of constant values for the distance variables behaves as WFG5, whereas
the behavior for the cases where the optimal regions consist of non-constant values for the distance variables are
more similar to the UF5 case.
%
Note however, that in these cases, different levels of diversity are required, so the behavior is not so homogeneous.

\begin{figure}[t]
\centering
\includegraphics[scale=0.70]{images/Graphic-Scalability-2obj_tikz-figure0.eps}
\caption{Mean of the \HV{} ratio for 35 runs for the two-objective problems considering different numbers of variables}\label{fig:scalability-2obj}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[scale=0.70]{images/Graphic-Scalability-3obj_tikz-figure0.eps}
\caption{Mean of the \HV{} ratio for 35 runs for the three-objective problems considering different numbers of variables} \label{fig:scalability-3obj}
\end{figure}

\subsection{Analysis of Scalability in the Decision Variables}

In order to have a better insight of the benefits of our proposal, an analysis of the scalability in terms of the number 
of decision variables is presented.
%
Given the computational cost associated to this experimentation, it was carried out considering only 
the decomposition-based algorithms.
%
\AVSDMOEAD{} and \MOEADDE{} were applied to the same benchmark problems than in the previous experiment, 
but considering $50$, $100$, $250$ and $500$ variables.
%
Note that in the WFG test problems, the number of position variables and distance variables must be specified.
%
Specifically, the number of distance variables was set to $42$, $84$, $210$ and $418$ when using $50$, $100$, $250$ and $500$ 
variables, respectively.
%
The rest of the decision variables were position variables, meaning that they were $8$, $16$, $40$ and $82$, respectively.
%
Thus, the relation between the number of position and distance variables is kept fixed.
%
In addition, the stopping criterion was set to $2.5 \times 10^7$ function evaluations.
%
Figures~\ref{fig:scalability-2obj} and~\ref{fig:scalability-3obj} show the mean \HV{} ratio for the selected algorithms, 
considering the problems with two and three objectives, respectively.
%
As expected, the \HV{} ratio decreases as the number of variables increases.
%
However, the performance of \AVSDMOEAD{} is quite robust and its decrease is less pronounced than the one in \MOEADDE{},
meaning that \AVSDMOEAD{} is more helpful as the complexity increases.
%
In fact, in our previous analyses the most remarkable performance of \AVSDMOEAD{} also appeared in the most complex cases such
as WFG8 and UF5.
%



\begin{figure}[t]
\centering
\includegraphics[scale=0.70]{images/Graphic-Initial-Distance_tikz-figure0.eps} \\
\caption{Mean of \HV{} values taking into account all the problems with several initial threshold values}\label{fig:Initial-distance-factor}
\end{figure}


\subsection{Analysis of the Initial Penalty Threshold}

Possibly, one of the main downsides of including a strategy to explicitly promoting the diversity 
is that this is usually at the cost of incorporating additional parameters.
%
In the case of \AVSDMOEAD{} it requires the setting of the initial penalty threshold ($D_I)$.
%
Given that in single-objective cases, values close to $0.4$ has attained proper performance~\cite{romero2018memetic,castillo2019differential},
$D_I = 0.4$ was used in our previous experiment.
%
This section provides a more detailed study on the implications of this parameter.
%

\begin{figure}[t]
\centering
\begin{tabular}{l}
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_WFG9-figure0.eps}\\[0cm]%[-0.14cm] 
 \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_WFG9-figure1.eps}\\[0cm]%[-0.14cm] 
\end{tabular}
\caption{Diversity of distance variables (top) and mean of \HV{} values (bottom) vs. elapsed time in the two-objective WFG9 test problem. The reported results are taken from $35$ runs.}\label{fig:WFG9_Diversity}
\end{figure}


%\begin{figure}[t]
%\centering
%\begin{tabular}{l}
% \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_UF10-figure0.eps}\\[0cm]%[-0.14cm] 
% \includegraphics[scale=0.75]{images/Diversity_Long_Term_tikz_UF10-figure1.eps}\\[0cm]%[-0.14cm] 
%\end{tabular}
%\caption{Diversity of distance variables (first row) and mean of \HV{} values (second row) vs. elapsed time in the three-objective UF10 test problem. The reported results are taken from $35$ runs.}\label{fig:UF10_Diversity}
%\end{figure}

In order to better understand the importance of $D_I$, the whole set of benchmark problems was tested with different values
of $D_I$.
%
As in previous experiments, the stopping criterion was set to $2.5 \times 10^7$ function evaluations.
%
Since normalized distances are used (see~\ref{eqn:distance}), the maximum attainable distance is $1.0$.
%
Also note that setting $D_I$ to $0$ implies not promoting diversity in the variable space.
%
Thus, several values in this range were considered.
%
Specifically, the values $D_I = \{0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0\}$ were tested.
%
Figure~\ref{fig:Initial-distance-factor} shows the mean \HV{} ratio obtained for both the two-objective 
and the three-objective case with the tested $D_I$ values.
%
The worst performance of the \AVSDMOEAD{} appears when $D_I$ is set to $0$.
%
The \HV{} ratio obtained quickly increases as higher $D_I$ values up to $0.2$ are used.
%
Larger values provide a quite similar performance.
%
Thus, there is a wide range of values (from $0.2$ to $1.0$) where a really good performance is attained, 
meaning that the behavior of \AVSDMOEAD{} is quite robust.
%
Thus, properly setting this parameter is not a complex task.

In order to better understand the implications of $D_I$ on the dynamics of the population Figure~\ref{fig:WFG9_Diversity}
shows for \AVSDMOEAD{} the evolution of diversity for \textsc{wfg9} on the distance variables for three different values of $D_I$.
%
When using $D_I = 0$, the diversity is reduced quite fastly which results in premature convergence.
%
Thus, a not too high hypervolume is attained.
%
However, when using $D_I = 0.4$ and $D_I = 1$ the loss of diversity is slowed down and quite a large hypervolume
is attained.
%
Note that the setting of $D_I = 1$ promotes a larger diversity so the hypervolume increases slower than when using
$D_I = 0.4$.
%
However, the exploration degree in both cases is enough to reach high-quality solutions.
%
The behavior is quite similar in all problems, which explains the stability of the algorithms for
different $D_I$ values.
%
Note that probably, for shorter periods the setting of a proper $D_I$ value might be much more important.
%
However, at least for long-term executions, practically any value larger than $0.2$ attains similar solutions,
which we consider a quite positive feature.


%Thereafter, in a more specifically way, the effect of this parameter is analized in WFG9 and UF10 test problems, in two and three objectives, respectively.
%
%In the same way than in the previous experiments, the Figures and~\ref{fig:UF10_Diversity} show the evolution of diversity (top side) and \HV{} ratio (bottom side) among the execution.
%
%The WFG9 test problem is multi-modal and deceptive.
%
%In addition, the UF10 test problem is highly multi-frontal and can be considered as one of the most challenging problems.
%
%Such diagrams belong to \AVSDMOEAD{} with the values $D_I = \{0.0, 0.4, 1.0\}$.
%
%Interestingly, the behavior of \AVSDMOEAD{} with $D_I=0.0$ is quite similar than the state-of-the-art \MOEAS{}, which confirms or previous claim.
%
%The motivation behind those diagrams is to ilustrate that to achieve a better balance between exploration and exploitation can be the explicit promotion of diversity among the execution.
%
%Therefore, those figures show that in multi-objective optimization --depending in each \MOP{}-- there is a relation between the diversity and the quality solutions, in fact visually the shapes of the \ADI{} and \HV{} ratio complement each other.
%
%Even more the \HV{} ratio values are constantly improving as the execution time elapses.
%


